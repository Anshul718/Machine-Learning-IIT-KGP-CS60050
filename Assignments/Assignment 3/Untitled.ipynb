{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-------------------> Classifier 1 <-------------------\n",
      "gender = female\n",
      "|\tpclass = 1st: yes\n",
      "gender = male\n",
      "|\tpclass = 1st\n",
      "|\t|\tage = adult:  yes\n",
      "|\t|\tage = child:  yes\n",
      "|\tpclass = 2nd\n",
      "|\t|\tage = adult:  no\n",
      "|\t|\tage = child:  yes\n",
      "|\tpclass = 3rd\n",
      "|\t|\tage = adult:  no\n",
      "|\t|\tage = child:  no\n",
      "|\tpclass = crew\n",
      "|\t|\tage = adult:  no\n",
      "|\t|\tage = child:  yes\n",
      "\n",
      "Accuracy : 0.6823255813953488\n",
      "\n",
      "-------------------> Classifier 2 <-------------------\n",
      "gender = female\n",
      "|\tpclass = 1st: yes\n",
      "gender = male\n",
      "|\tpclass = 1st: yes\n",
      "\n",
      "Accuracy : 0.0051162790697674414\n",
      "\n",
      "-------------------> Classifier 3 <-------------------\n",
      "gender = female\n",
      "|\tpclass = 1st: yes\n",
      "gender = male\n",
      "|\tpclass = 1st: yes\n",
      "\n",
      "Accuracy : 0.0018604651162790699\n",
      "\n",
      "================> COMBINED CLASSIFIER <=============== \n",
      "Final Accuracy : 0.4307692307692308\n"
     ]
    }
   ],
   "source": [
    "##########\tName - Anshul Choudhary\n",
    "##########\tRoll - 17CS10005\n",
    "##########\tAssignment - 3 (AdaBoost)\n",
    "\n",
    "import numpy\n",
    "import math\n",
    "from numpy import genfromtxt\n",
    "\n",
    "## main\n",
    "data = genfromtxt('data3_19.csv', delimiter=',', dtype = str)\n",
    "\n",
    "TE = data[1:,]\n",
    "TE_X = data[1:,0:3]\n",
    "TE_Y = data[1:,3]\n",
    "TE_Y.shape = (TE_X.shape[0],1)\n",
    "\n",
    "prob = []\n",
    "indexArray = []\n",
    "\n",
    "for i in range(0,TE.shape[0]):\n",
    "\tprob.append(1/TE.shape[0])\n",
    "\tindexArray.append(i)\n",
    "    \n",
    "treeArray = []\n",
    "class_weights = []\n",
    "y_array = []\n",
    "\n",
    "for k in range(1,4):\n",
    "\t\n",
    "\trandomSample = numpy.random.choice(indexArray,TE.shape[0],True,prob)\n",
    "\t\n",
    "\tTE_sample = TE[:]\n",
    "\tfor i in range(0,TE.shape[0]):\n",
    "\t\tTE_sample[i] = TE[randomSample[i]]\n",
    "        \n",
    "\tprint(\"\\n-------------------> Classifier \" + str(k) + \" <-------------------\")\n",
    "\tfeatures = data[0,0:3]\n",
    "\tfeat_categs = []\n",
    "\n",
    "\tindent = \"\"\n",
    "\n",
    "\t\n",
    "\tfor i in range(0,3):\n",
    "\t\tfeat_categs.append(numpy.unique(TE_X[:,i]))\n",
    "\t\n",
    "\tTE_sample_X = TE_sample[:,0:3]\n",
    "\tTE_sample_Y = TE_sample[:,3]\n",
    "\tY_T = TE_sample[:,3]\n",
    "\tTE_sample_Y.shape = (TE_sample_X.shape[0],1)\n",
    "    \n",
    "\troot_node = GenerateDecisionTree(TE_sample,TE_sample_X,TE_sample_Y,feat_categs,features,indent)\n",
    "\ttreeArray.append(root_node)\n",
    "    \n",
    "\tfeatures = features.tolist()\n",
    "\t\n",
    "\tpred_Y = Generate_Classifier(TE_sample_X,root_node,features)\n",
    "\t\n",
    "\tY_T = Y_T.tolist()\n",
    "\t\n",
    "\tcorr_count = 0\n",
    "\tfor i in range(0,len(pred_Y)):\n",
    "\t\tif(pred_Y[i] == Y_T[i]):\n",
    "\t\t\tcorr_count += 1\n",
    "\t\n",
    "\ttest_count = len(pred_Y)\n",
    "\tprint(\"\\nAccuracy : \"+str(corr_count/test_count) )\n",
    "\n",
    "\tE = 1 - (corr_count/test_count)\n",
    "\tclass_weights.append(get_classifier_Weight(E))\n",
    "\tprob = update_weights(prob,TE_sample_Y,pred_Y,curr_wt)\n",
    "    \n",
    "    \n",
    "\n",
    "print(\"\\n================> COMBINED CLASSIFIER <=============== \")\n",
    "\n",
    "data_test = genfromtxt('test3_19.csv', delimiter=',', dtype = str)\n",
    "Test_X = data_test[1:,0:3]\n",
    "Test_Y = data_test[1:,3]\n",
    "Test_Y = Test_Y.tolist()\n",
    "\n",
    "\n",
    "y_p = []\n",
    "for i in range(0,3):\n",
    "\ty_p = Generate_Classifier(Test_X,treeArray[i],features)\n",
    "\ty_array.append(y_p)\n",
    "    \n",
    "y_array = numpy.asarray(y_array)\n",
    "y_array = numpy.transpose(y_array)\n",
    "\n",
    "y_out = finalOutput(class_weights,y_array)\n",
    "#print(y_out)\n",
    "\n",
    "n_test = len(Test_Y)\n",
    "c = 0\n",
    "for i in range(0,len(y_out)):\n",
    "\tif(y_out[i] == Test_Y[i]):\n",
    "\t\tc += 1\n",
    "\n",
    "print(\"Final Accuracy : \"+str(c/n_test))\n",
    "\n",
    "\n",
    "####################### Funcions #######################\n",
    "\n",
    "class Node:\n",
    "\tdef __init__(self): \n",
    "\t\tself.label = \"\"\n",
    "\t\tself.next = None\n",
    "\t\tself.child_nodes = [] \n",
    "\n",
    "#To calculate entropy\n",
    "def Entropy(TE_Y):\n",
    "\treject_Y = TE_Y[numpy.where(TE_Y[:,0] == 'no')]\n",
    "\taccept_Y = TE_Y[numpy.where(TE_Y[:,0] == 'yes')]\n",
    "\n",
    "\tcount_accY = accept_Y.shape[0]\n",
    "\tcount_rejY = reject_Y.shape[0]\n",
    "\n",
    "\tcount = count_accY + count_rejY\n",
    "\tif(count == 0):\n",
    "\t\treturn 0\n",
    "\tprob_accY = count_accY / (count)\n",
    "\tprob_rejY = count_rejY / (count)\n",
    "\n",
    "\tif(prob_accY == 0):\n",
    "\t\tprob_accY = 0.0000000001\n",
    "\tif(prob_rejY == 0):\n",
    "\t\tprob_rejY = 0.0000000001\n",
    "\t\t\n",
    "\treturn -(prob_accY * numpy.log(prob_accY)) - (prob_rejY * numpy.log(prob_rejY))\n",
    "\n",
    "\n",
    "def Gain(TE,S,categ,index):\n",
    "\tn = TE.shape[0]\n",
    "\tsum = 0\n",
    "\tfor catg in categ:\n",
    "\t\tsub_TE = TE[numpy.where(TE[:,index] == catg)]\n",
    "\t\tTE_Y = sub_TE[:,sub_TE.shape[1]-1]\n",
    "\t\tTE_Y.shape = (len(TE_Y),1)\n",
    "\t\tcount_Y = TE_Y.shape[0]\n",
    "\t\tsum += (count_Y/n) * Entropy(TE_Y)\n",
    "\n",
    "\treturn Entropy(S) - sum\n",
    "\n",
    "\n",
    "def GenerateDecisionTree(TE,TE_X,TE_Y,feat_categs,features,indent):\n",
    "\t\n",
    "\tfeat_count = TE_X.shape[1]\n",
    "\troot_node = Node()\n",
    "\n",
    "\tif(feat_count == 1):\n",
    "\t\tindex = 0\n",
    "\n",
    "\t\troot_node.label = features[index]\n",
    "\t\tfor categ in feat_categs[0]:\n",
    "\t\t\tcurr = Node()\n",
    "\t\t\tcurr.label = categ\n",
    "\t\t\troot_node.child_nodes.append(curr)\n",
    "\n",
    "\t\t\tsub_TE = TE[numpy.where(TE[:,index] == categ)]\n",
    "\t\t\taccept_TE = sub_TE[numpy.where(sub_TE[:,1] == 'yes')]\n",
    "\t\t\treject_TE = sub_TE[numpy.where(sub_TE[:,1] == 'no')]\n",
    "\n",
    "\t\t\tprint(indent + features[index] + \" = \" + categ + \": \",end = \" \")\n",
    "\n",
    "\t\t\tnode_val = Node()\n",
    "\t\t\tnode_val.label = \"yes\"\n",
    "\n",
    "\t\t\tif(accept_TE.shape[0] == 0 and reject_TE.shape[0] == 0):\n",
    "\t\t\t\troot_node.child_nodes[len(root_node.child_nodes) - 1].next = node_val\n",
    "\t\t\t\tprint(\"yes\")\n",
    "\t\t\t\tcontinue\n",
    "\t\t\tif(accept_TE.shape[0] > reject_TE.shape[0]):\n",
    "\t\t\t\troot_node.child_nodes[len(root_node.child_nodes) - 1].next = node_val\n",
    "\t\t\t\tprint(\"yes\")\n",
    "\t\t\telse:\n",
    "\t\t\t\tnode_val.label = \"no\"\n",
    "\t\t\t\troot_node.child_nodes[len(root_node.child_nodes) - 1].next = node_val\n",
    "\t\t\t\tprint(\"no\")\n",
    "\t\n",
    "\telse:\n",
    "\t\tindex = 0\n",
    "\t\tmax_gain = 0\n",
    "\t\t\n",
    "\t\tfor i in range(0,feat_count):\n",
    "\t\t\tgain = Gain(TE,TE_Y,feat_categs[i],i)\n",
    "\t\t\tif(gain > max_gain):\n",
    "\t\t\t   max_gain = gain\n",
    "\t\t\t   index = i\n",
    "\t\troot_node.label = features[index]\n",
    "\t\t\n",
    "\t\tfor categ in feat_categs[index]:\n",
    "\t\t\tcurr = Node()\n",
    "\t\t\tcurr.label = categ\n",
    "\t\t\troot_node.child_nodes.append(curr)\n",
    "\n",
    "\t\t\tsub_TE = TE[numpy.where(TE[:,index] == categ)]\n",
    "\n",
    "\t\t\tl = sub_TE.shape[1]\n",
    "\t\t\tif(sub_TE.shape[0] == 0):\n",
    "\t\t\t   continue\n",
    "\n",
    "\t\t\taccept_TE = sub_TE[numpy.where(sub_TE[:,l-1] == 'yes')]\n",
    "\t\t\treject_TE = sub_TE[numpy.where(sub_TE[:,l-1] == 'no')]\n",
    "\n",
    "\t\t\tnode_val = Node()\n",
    "\t\t\tnode_val.label = \"yes\"\n",
    "\n",
    "\t\t\tif(accept_TE.shape[0] == 0):\n",
    "\t\t\t   node_val.label = \"no\"\n",
    "\t\t\t   root_node.child_nodes[len(root_node.child_nodes) - 1].next = node_val\n",
    "\t\t\t   print(indent + features[index] + \" = \" + categ + \": no\")\n",
    "\t\t\t   break\n",
    "\t\t\telif(reject_TE.shape[0] == 0):\n",
    "\t\t\t   root_node.child_nodes[len(root_node.child_nodes) - 1].next = node_val\n",
    "\t\t\t   print(indent + features[index] + \" = \" + categ + \": yes\")\n",
    "\t\t\t   break\n",
    "\t\t\t\n",
    "\t\t\tnew_TE = numpy.delete(sub_TE , index, axis=1)\n",
    "\t\t\tl = new_TE.shape[1]\n",
    "\t\t\tX_new = new_TE[:,0:l - 1]\n",
    "\t\t\ty_new = new_TE[:,l-1]\n",
    "\t\t\ty_new.shape = (len(y_new),1)\n",
    "\t\t\tnew_features = numpy.delete(features,index)\n",
    "\t\t\tnew_categs = numpy.delete(feat_categs,index)\n",
    "\t\t\t\n",
    "\t\t\tprint(indent + features[index] + \" = \" + categ)\n",
    "\n",
    "\t\t\troot_node.child_nodes[len(root_node.child_nodes) - 1].next = GenerateDecisionTree(new_TE,X_new,y_new,new_categs,new_features,indent + \"|\t\")\n",
    "\treturn root_node\n",
    "\n",
    "\n",
    "def DFS(Test_X,root_node,features):\n",
    "\tif(root_node == None):\n",
    "\t\treturn \"\"\n",
    "\tif(len(root_node.child_nodes) == 0):\n",
    "\t\tif(root_node.label == \"yes\" or root_node.label == \"no\"):\n",
    "\t\t\treturn root_node.label\n",
    "\t\telse:\n",
    "\t\t\treturn \"\"\n",
    "\ti = features.index(root_node.label)\n",
    "\tfor var in root_node.child_nodes:\n",
    "\t\tif(Test_X[i] == var.label):\n",
    "\t\t\treturn DFS(Test_X,var.next,features)\n",
    "\treturn \"\"\n",
    "\n",
    "def Generate_Classifier(Test_X,root_node,features):\n",
    "\ty_out = []\n",
    "\tfor i in range(0,Test_X.shape[0]):\n",
    "\t\ty_out.append(DFS(Test_X[i],root_node,features))\n",
    "\treturn y_out\n",
    "\n",
    "\n",
    "\n",
    "###  ADABOOST  ###\n",
    "\n",
    "def get_classifier_Weight(error):\n",
    "\tif(error == 0):\n",
    "\t\terror = 0.0000000001\n",
    "\telif(error == 1):\n",
    "\t\terror = 1 - 0.0000000001; \n",
    "\n",
    "\treturn 0.5 * numpy.log((1 - error)/error)\n",
    "\n",
    "\n",
    "def finalOutput(class_weights,y_array):\n",
    "\tpred_Y = []\n",
    "\tfor i in range(0,y_array.shape[0]):\n",
    "\t\tpos_weight = 0\n",
    "\t\tneg_weight = 0\n",
    "\t\tfor j in range(1,y_array.shape[1]):\n",
    "\t\t\tif(y_array[i][j] == \"yes\"):\n",
    "\t\t\t\tpos_weight += class_weights[j]\n",
    "\t\t\telse:\n",
    "\t\t\t\tneg_weight += class_weights[j]\n",
    "\t\tif(pos_weight > neg_weight):\n",
    "\t\t\tpred_Y.append(\"yes\")\n",
    "\t\telse:\n",
    "\t\t\tpred_Y.append(\"no\")\n",
    "\treturn pred_Y\n",
    "\n",
    "\n",
    "def update_weights(weight_list,Test_Y,pred_Y,class_weight):\n",
    "\tTotal_Weight = 0\n",
    "\tfor i in range(0,len(weight_list)):\n",
    "\t\tf = -1\n",
    "\t\tif(Test_Y[i] == pred_Y[i]):\n",
    "\t\t\tf = 1\n",
    "\t\t\t\n",
    "\t\tweight_list[i] = weight_list[i] * math.exp(-1 * f * class_weight)\n",
    "\t\tTotal_Weight += weight_list[i]\n",
    "\n",
    "\tfor i in range(0,len(weight_list)):\n",
    "\t\tweight_list[i] = weight_list[i]/Total_Weight\n",
    "\t\n",
    "\treturn weight_list\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
